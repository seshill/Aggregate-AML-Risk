{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zvDNP-06TPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aa90d17-05e0-4473-b6f0-0ee39acbfe83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import dataset and create two data frames: X containing only exposure amounts, y containing only the outcomes (1s and 0s)"
      ],
      "metadata": {
        "id": "I25oDIzv9W9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Undergrad/Thesis/Artificial_Dataset_1.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=['Individual', 'AMLoutcome']).values  # Exposure columns only\n",
        "y = df['AMLoutcome'].values  # Target variable (AML outcome), 1s and 0s"
      ],
      "metadata": {
        "id": "xpNVFQP88xQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define SMOTE and Undersampling Pipeline"
      ],
      "metadata": {
        "id": "kFUUCw6y9h32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "bwwA6hM79vhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define SMOTE and undersampler in a pipeline\n",
        "smote = SMOTE(sampling_strategy=0.5)  # Create 0.5 synthetic samples for every real sample in AML-negative\n",
        "undersample = RandomUnderSampler(sampling_strategy=0.8)  # Keep 80% of the AML-negative cases\n",
        "\n",
        "pipeline = Pipeline([('smote', smote), ('undersample', undersample)])"
      ],
      "metadata": {
        "id": "5j1YLrD59Sg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply the Pipeline to Resample Data"
      ],
      "metadata": {
        "id": "d1-7WnlR9zGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply transformations using pipeline defined above\n",
        "X_resampled, y_resampled = pipeline.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "J0gnuW1492Zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the data frames into PyTorch tensors, define data loader"
      ],
      "metadata": {
        "id": "ZTXsvwMt_ZEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "R1TEI7Lm_ip7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert resampled data to tensors for PyTorch\n",
        "X_resampled = torch.tensor(X_resampled, dtype=torch.float32)\n",
        "y_resampled = torch.tensor(y_resampled, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "-BZpJF6n_jPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define DataLoader with balanced data\n",
        "dataset_resampled = TensorDataset(X_resampled, y_resampled)\n",
        "data_loader = DataLoader(dataset_resampled, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "Ism20B1-_nvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Model with MSE Loss"
      ],
      "metadata": {
        "id": "JyhEtE3qAkzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Array of IUR values\n",
        "IUR = np.array([3.03E-12, 1.25E-14, 1.09E-14, 2.24E-15, 1.25E-14, 1.34E-14, 1.68E-15, 4.33E-15])"
      ],
      "metadata": {
        "id": "zAuwNAe9C0Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "zCYCGOfXAw41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize coefficients and exponents as trainable parameters\n",
        "coefficients = torch.ones(8, requires_grad=True) # 8 because there are 8 substances\n",
        "exponents = torch.ones(8, requires_grad=True)\n",
        "\n",
        "interactions = torch.ones(28, requires_grad=True) # 28 interaction pairs... 8 choose 2\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = optim.Adam([coefficients, exponents], lr=0.01)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# List to store loss values\n",
        "loss_history = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1000):  # Number of epochs\n",
        "    epoch_loss = 0  # Accumulate loss over batches in the epoch\n",
        "    for batch_features, batch_targets in data_loader:\n",
        "        # Calculate the risk based on current coefficients and exponents\n",
        "        calculated_risk = sum(\n",
        "            coefficients[i] * (IUR[i] * batch_features[:, i]) ** exponents[i] for i in range(8)\n",
        "        )\n",
        "\n",
        "        # Calculate MSE loss\n",
        "        loss = F.mse_loss(calculated_risk, batch_targets)\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate batch loss\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    # Average loss for the epoch\n",
        "    avg_epoch_loss = epoch_loss / len(data_loader)\n",
        "    loss_history.append(avg_epoch_loss)\n",
        "\n",
        "    # Print loss every 100 epochs\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {avg_epoch_loss}')\n",
        "\n",
        "# Plot loss history\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, 1001), loss_history, label=\"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Over Epochs\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-4f-aidoAoEK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5106acf3-6d0b-445a-c512-0d8f1cd7317d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.5454545617103577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessing Learned Parameters"
      ],
      "metadata": {
        "id": "BcNfe92_I_Ek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# List of substance names\n",
        "substance_names = [\n",
        "    \"PAH (polycyclic aromatic hydrocarbon)\", \"1,3-Butadiene\", \"O-Xylene\", \"Benzene\",\n",
        "    \"Toluene\", \"Styrene\", \"p-dichloro\", \"Chloroform\"\n",
        "]\n",
        "\n",
        "# Extract values from tensors\n",
        "coefficients_values = coefficients.detach().numpy()\n",
        "exponents_values = exponents.detach().numpy()\n",
        "\n",
        "# Create a DataFrame\n",
        "data = {\n",
        "    \"Substance\": substance_names,\n",
        "    \"Coefficient\": coefficients_values,\n",
        "    \"Exponent\": exponents_values\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save to CSV\n",
        "csv_path = \"learned_parameters.csv\"\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"File saved at {csv_path}\")\n"
      ],
      "metadata": {
        "id": "2MBCb5Y3JD9-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}